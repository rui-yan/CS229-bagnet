{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fmodern\fcharset0 CourierNewPS-BoldMT;\f1\fmodern\fcharset0 CourierNewPSMT;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red23\green175\blue15;
\red255\green255\blue255;\red97\green142\blue197;\red255\green255\blue255;\red255\green255\blue255;\red255\green255\blue255;
\red255\green255\blue255;\red255\green255\blue255;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000\c0;\cssrgb\c0\c72208\c6472;
\cssrgb\c100000\c100000\c99956;\cssrgb\c45257\c62992\c81647;\cssrgb\c100000\c100000\c99956;\cssrgb\c100000\c100000\c99926;\cssrgb\c100000\c100000\c99926;
\cssrgb\c100000\c100000\c99971;\cssrgb\c100000\c100000\c99985;\cssrgb\c100000\c100000\c99941;}
\margl1440\margr1440\vieww27500\viewh13780\viewkind0
\deftab720
\pard\pardeftab720\sl300\partightenfactor0

\f0\b\fs26 \AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 jiyingzou@cnn-patch-project-vm
\f1\b0 \AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \strokec5 :
\f0\b \AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \strokec6 ~/CS229-final-project/CS229-final-project
\f1\b0 \AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \strokec5 $ python run_resnet50.py\
PyTorch Version:  1.2.0\
Torchvision Version:  0.4.0a0+6b959ee\
[Using cuda:0 ...]\
==> [Preparing data ....]\
Initializing Datasets and Dataloaders...\
==> Resnet-50 model\
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /home/jiyingzou/.cache/torch/checkpoint\
s/resnet50-19c8e357.pth\
100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 97.8M/97.8M [00:01<00:00, 81.4MB/s]\
Linear(in_features=2048, out_features=5, bias=True)\
Params to learn:\
         fc.weight\
         fc.bias\
[Using CrossEntropyLoss ...]\
[Training the model begun ...]\
Epoch 0/99\
----------\
train Loss: 1.0693 Acc: 0.6290\
val Loss: 0.9206 Acc: 0.5760\
\
Epoch 1/99\
----------\
train Loss: 0.8242 Acc: 0.6977\
val Loss: 0.7974 Acc: 0.7102\
\
Epoch 2/99\
----------\
train Loss: 0.7928 Acc: 0.7108\
val Loss: 0.7787 Acc: 0.7106\
\
Epoch 3/99\
----------\
train Loss: 0.7886 Acc: 0.7106\
val Loss: 0.7773 Acc: 0.7106\
\
Epoch 4/99\
----------\
train Loss: 0.7834 Acc: 0.7108\
val Loss: 0.7722 Acc: 0.7104\
\
Epoch 5/99\
----------\
train Loss: 0.7784 Acc: 0.7108\
val Loss: 0.7730 Acc: 0.7108\
\
Epoch 6/99\
----------\
train Loss: 0.7777 Acc: 0.7108\
val Loss: 0.7732 Acc: 0.7108\
\
Epoch 7/99\
----------\
train Loss: 0.7735 Acc: 0.7108\
val Loss: 0.7671 Acc: 0.7108\
\
Epoch 8/99\
----------\
train Loss: 0.7709 Acc: 0.7108\
val Loss: 0.7660 Acc: 0.7104\
\
Epoch 9/99\
----------\
train Loss: 0.7709 Acc: 0.7106\
val Loss: 0.7649 Acc: 0.7106\
\
Epoch 10/99\
----------\
train Loss: 0.7732 Acc: 0.7111\
val Loss: 0.7635 Acc: 0.7108\
\
Epoch 11/99\
----------\
train Loss: 0.7723 Acc: 0.7111\
val Loss: 0.7625 Acc: 0.7108\
\
Epoch 12/99\
----------\
train Loss: 0.7727 Acc: 0.7108\
val Loss: 0.7652 Acc: 0.7108\
\
Epoch 13/99\
----------\
train Loss: 0.7729 Acc: 0.7108\
val Loss: 0.7614 Acc: 0.7108\
\
Epoch 14/99\
----------\
train Loss: 0.7655 Acc: 0.7108\
val Loss: 0.7607 Acc: 0.7108\
\
Epoch 15/99\
----------\
train Loss: 0.7691 Acc: 0.7106\
val Loss: 0.7750 Acc: 0.7108\
\
Epoch 16/99\
----------\
train Loss: 0.7706 Acc: 0.7106\
val Loss: 0.7600 Acc: 0.7108\
\
Epoch 17/99\
----------\
train Loss: 0.7638 Acc: 0.7108\
val Loss: 0.7602 Acc: 0.7108\
\
Epoch 18/99\
----------\
train Loss: 0.7637 Acc: 0.7108\
val Loss: 0.7573 Acc: 0.7108\
\
Epoch 19/99\
----------\
train Loss: 0.7648 Acc: 0.7106\
val Loss: 0.7572 Acc: 0.7108\
\
Epoch 20/99\
----------\
train Loss: 0.7672 Acc: 0.7108\
val Loss: 0.7558 Acc: 0.7108\
\
Epoch 21/99\
----------\
train Loss: 0.7622 Acc: 0.7108\
val Loss: 0.7551 Acc: 0.7108\
\
Epoch 22/99\
----------\
train Loss: 0.7632 Acc: 0.7108\
val Loss: 0.7550 Acc: 0.7111\
\
Epoch 23/99\
----------\
train Loss: 0.7627 Acc: 0.7108\
val Loss: 0.7566 Acc: 0.7108\
\
Epoch 24/99\
----------\
train Loss: 0.7618 Acc: 0.7111\
val Loss: 0.7595 Acc: 0.7108\
\
Epoch 25/99\
----------\
train Loss: 0.7603 Acc: 0.7108\
val Loss: 0.7525 Acc: 0.7111\
\
Epoch 26/99\
----------\
train Loss: 0.7645 Acc: 0.7104\
val Loss: 0.7524 Acc: 0.7108\
\
Epoch 27/99\
----------\
train Loss: 0.7579 Acc: 0.7108\
val Loss: 0.7555 Acc: 0.7108\
\
Epoch 28/99\
----------\
train Loss: 0.7588 Acc: 0.7111\
val Loss: 0.7508 Acc: 0.7111\
\
Epoch 29/99\
----------\
train Loss: 0.7579 Acc: 0.7108\
val Loss: 0.7522 Acc: 0.7113\
\
Epoch 30/99\
----------\
train Loss: 0.7592 Acc: 0.7106\
val Loss: 0.7500 Acc: 0.7111\
\
Epoch 31/99\
----------\
train Loss: 0.7578 Acc: 0.7108\
val Loss: 0.7514 Acc: 0.7113\
\
Epoch 32/99\
----------\
train Loss: 0.7600 Acc: 0.7111\
val Loss: 0.7509 Acc: 0.7113\
\
Epoch 33/99\
----------\
train Loss: 0.7591 Acc: 0.7111\
val Loss: 0.7503 Acc: 0.7115\
\
Epoch 34/99\
----------\
train Loss: 0.7597 Acc: 0.7120\
val Loss: 0.7489 Acc: 0.7111\
\
Epoch 35/99\
----------\
train Loss: 0.7606 Acc: 0.7106\
val Loss: 0.7501 Acc: 0.7111\
\
Epoch 36/99\
----------\
train Loss: 0.7587 Acc: 0.7106\
val Loss: 0.7488 Acc: 0.7111\
\
\pard\pardeftab720\sl300\partightenfactor0
\AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \outl0\strokewidth0 Epoch 37/99\
----------\
\cf2 \cb3 train Loss: 0.7587 Acc: 0.7106\AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \outl0\strokewidth0 \strokec9 \
\pard\pardeftab720\sl300\partightenfactor0
\cf2 \cb3 \strokec10 val Loss: 0.7527 Acc: 0.7111\
\
Epoch 38/99\
----------\
train Loss: 0.7567 Acc: 0.7111\
val Loss: 0.7471 Acc: 0.7111\
\
Epoch 39/99\
----------\
train Loss: 0.7562 Acc: 0.7111\
val Loss: 0.7470 Acc: 0.7111\cf11 \cb3 \strokec11 \
\cf2 \cb3 \strokec12 \
\cf2 \cb3 \strokec5 Epoch 40/99\
----------\
train Loss: 0.7558 Acc: 0.7108\
val Loss: 0.7460 Acc: 0.7113\
\
Epoch 41/99\
----------\
train Loss: 0.7560 Acc: 0.7111\
val Loss: 0.7490 Acc: 0.7111\
\
Epoch 42/99\
----------\
train Loss: 0.7560 Acc: 0.7113\
val Loss: 0.7454 Acc: 0.7111\
\
Epoch 43/99\
----------\
train Loss: 0.7540 Acc: 0.7111\
val Loss: 0.7456 Acc: 0.7113\
\
Epoch 44/99\
----------\
train Loss: 0.7555 Acc: 0.7111\
val Loss: 0.7470 Acc: 0.7115\
\
\pard\pardeftab720\sl300\partightenfactor0
\AppleTypeServices\AppleTypeServicesF65539 \cf2 \cb3 \strokec9 Epoch 45/99\
----------\
train Loss: 0.7543 Acc: 0.7108\
val Loss: 0.7469 Acc: 0.7113\
\
Epoch 46/99\
----------\
train Loss: 0.7531 Acc: 0.7111\
val Loss: 0.7444 Acc: 0.7113\
\
Epoch 47/99\
----------\
train Loss: 0.7538 Acc: 0.7113\
val Loss: 0.7476 Acc: 0.7118\
\
Epoch 48/99\
----------\
train Loss: 0.7535 Acc: 0.7108\
val Loss: 0.7435 Acc: 0.7115\
\
Epoch 49/99\
----------\
train Loss: 0.7521 Acc: 0.7118\
val Loss: 0.7493 Acc: 0.7108\
\
Epoch 50/99\
----------\
train Loss: 0.7563 Acc: 0.7108\
val Loss: 0.7481 Acc: 0.7111\
\
Epoch 51/99\
----------\
train Loss: 0.7515 Acc: 0.7106\
val Loss: 0.7522 Acc: 0.7108\
\
Epoch 52/99\
----------\
train Loss: 0.7569 Acc: 0.7108\
val Loss: 0.7482 Acc: 0.7111\
\
\pard\pardeftab720\sl300\partightenfactor0
\cf2 \cb3 \strokec9 Epoch 53/99\
----------\
train Loss: 0.7531 Acc: 0.7111\
val Loss: 0.7430 Acc: 0.7111\
\
Epoch 54/99\
----------\
train Loss: 0.7489 Acc: 0.7111\
val Loss: 0.7434 Acc: 0.7113\
\
Epoch 55/99\
----------\
train Loss: 0.7534 Acc: 0.7108\
val Loss: 0.7415 Acc: 0.7115\
\
Epoch 56/99\
----------\
train Loss: 0.7516 Acc: 0.7111\
val Loss: 0.7453 Acc: 0.7113\
\
Epoch 57/99\
----------\
train Loss: 0.7552 Acc: 0.7120\
val Loss: 0.7454 Acc: 0.7115\
\
Epoch 58/99\
----------\
train Loss: 0.7505 Acc: 0.7108\
val Loss: 0.7446 Acc: 0.7113\
\
Epoch 59/99\
----------\
train Loss: 0.7575 Acc: 0.7108\
val Loss: 0.7427 Acc: 0.7113\
\
Epoch 60/99\
----------\
train Loss: 0.7513 Acc: 0.7099\
val Loss: 0.7446 Acc: 0.7118\
\
Epoch 61/99\
----------\
\pard\pardeftab720\sl300\partightenfactor0
\cf2 \cb3 \strokec9 train Loss: 0.7487 Acc: 0.7115\
val Loss: 0.7401 Acc: 0.7118\
\
Epoch 62/99\
----------\
train Loss: 0.7499 Acc: 0.7108\
val Loss: 0.7390 Acc: 0.7115\
\
Epoch 63/99\
----------\
train Loss: 0.7503 Acc: 0.7115\
val Loss: 0.7396 Acc: 0.7113\
\
Epoch 64/99\
----------\
train Loss: 0.7535 Acc: 0.7102\
val Loss: 0.7397 Acc: 0.7115\
\
Epoch 65/99\
----------\
train Loss: 0.7503 Acc: 0.7111\
val Loss: 0.7387 Acc: 0.7113\
\
Epoch 66/99\
----------\
train Loss: 0.7491 Acc: 0.7108\
val Loss: 0.7392 Acc: 0.7113\
\
Epoch 67/99\
----------\
train Loss: 0.7500 Acc: 0.7102\
val Loss: 0.7378 Acc: 0.7115\
\
Epoch 68/99\
----------\
train Loss: 0.7457 Acc: 0.7102\
val Loss: 0.7405 Acc: 0.7115\
\
Epoch 69/99\
----------\
train Loss: 0.7485 Acc: 0.7111\
val Loss: 0.7460 Acc: 0.7111\
\
Epoch 70/99\
----------\
train Loss: 0.7502 Acc: 0.7106\
val Loss: 0.7399 Acc: 0.7111\
\
Epoch 71/99\
----------\
train Loss: 0.7490 Acc: 0.7113\
val Loss: 0.7398 Acc: 0.7111\
\
Epoch 72/99\
----------\
train Loss: 0.7467 Acc: 0.7111\
val Loss: 0.7401 Acc: 0.7111\
\
Epoch 73/99\
----------\
train Loss: 0.7464 Acc: 0.7125\
val Loss: 0.7468 Acc: 0.7111\
\
Epoch 74/99\
----------\
train Loss: 0.7505 Acc: 0.7113\
val Loss: 0.7380 Acc: 0.7113\
\
Epoch 75/99\
----------\
train Loss: 0.7490 Acc: 0.7102\
val Loss: 0.7369 Acc: 0.7113\
\
Epoch 76/99\
----------\
train Loss: 0.7467 Acc: 0.7108\
val Loss: 0.7362 Acc: 0.7113\
\
Epoch 77/99\
----------\
train Loss: 0.7466 Acc: 0.7108\
val Loss: 0.7368 Acc: 0.7115\
\
Epoch 78/99\
----------\
train Loss: 0.7483 Acc: 0.7111\
val Loss: 0.7356 Acc: 0.7118\
\
Epoch 79/99\
----------\
train Loss: 0.7485 Acc: 0.7115\
val Loss: 0.7373 Acc: 0.7113\
\
Epoch 80/99\
----------\
train Loss: 0.7437 Acc: 0.7113\
val Loss: 0.7350 Acc: 0.7115\
\
Epoch 81/99\
----------\
train Loss: 0.7466 Acc: 0.7106\
val Loss: 0.7361 Acc: 0.7113\
\
Epoch 82/99\
----------\
train Loss: 0.7436 Acc: 0.7111\
val Loss: 0.7357 Acc: 0.7115\
\
Epoch 83/99\
----------\
train Loss: 0.7405 Acc: 0.7108\
val Loss: 0.7342 Acc: 0.7118\
\
Epoch 84/99\
----------\
train Loss: 0.7467 Acc: 0.7118\
val Loss: 0.7351 Acc: 0.7118\
\
Epoch 85/99\
----------\
train Loss: 0.7432 Acc: 0.7115\
val Loss: 0.7341 Acc: 0.7118\
\
Epoch 86/99\
----------\
train Loss: 0.7448 Acc: 0.7113\
val Loss: 0.7335 Acc: 0.7118\
\
Epoch 87/99\
----------\
train Loss: 0.7466 Acc: 0.7113\
val Loss: 0.7331 Acc: 0.7118\
\
Epoch 88/99\
----------\
train Loss: 0.7421 Acc: 0.7111\
val Loss: 0.7333 Acc: 0.7118\
\
Epoch 89/99\
----------\
train Loss: 0.7416 Acc: 0.7122\
val Loss: 0.7331 Acc: 0.7122\
\
Epoch 90/99\
----------\
train Loss: 0.7416 Acc: 0.7104\
val Loss: 0.7331 Acc: 0.7120\
\
Epoch 91/99\
----------\
train Loss: 0.7454 Acc: 0.7097\
val Loss: 0.7351 Acc: 0.7120\
\
Epoch 92/99\
----------\
train Loss: 0.7455 Acc: 0.7115\
val Loss: 0.7323 Acc: 0.7118\
\
Epoch 93/99\
----------\
train Loss: 0.7416 Acc: 0.7118\
val Loss: 0.7321 Acc: 0.7118\
Epoch 94/99\
----------\
train Loss: 0.7438 Acc: 0.7111\
val Loss: 0.7329 Acc: 0.7113\
\
Epoch 95/99\
----------\
train Loss: 0.7415 Acc: 0.7111\
val Loss: 0.7319 Acc: 0.7118\
\
Epoch 96/99\
----------\
train Loss: 0.7426 Acc: 0.7122\
val Loss: 0.7356 Acc: 0.7113\
\
Epoch 97/99\
----------\
train Loss: 0.7452 Acc: 0.7111\
val Loss: 0.7330 Acc: 0.7113\
\
Epoch 98/99\
----------\
train Loss: 0.7413 Acc: 0.7122\
val Loss: 0.7409 Acc: 0.7111\
\
Epoch 99/99\
----------\
train Loss: 0.7484 Acc: 0.7115\
val Loss: 0.7399 Acc: 0.7111\
\
Training complete in 133m 34s\
Best val Acc: 0.712237\
\pard\pardeftab720\sl300\partightenfactor0
\cf2 \cb3 \strokec9 \
}