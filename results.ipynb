{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[libraries successfully installed...]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS FILE CONTAINS CODE TO EVALUATE THE SAVED RESNET-50 MODEL ON THE TEST SET.\n",
    "\n",
    "CREDITS: Much of this code was selectively borrowed and adapted from: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "train_on_gpu = True\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "try:\n",
    "    import torchbearer\n",
    "except:\n",
    "    !pip install torchbearer\n",
    "    import torchbearer\n",
    "from torchbearer import Trial\n",
    "import scipy\n",
    "import scipy.special\n",
    "import bagnets.pytorchnet\n",
    "print(\"[libraries successfully installed...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory\n",
    "data_dir = './flowers_tvtsplit/'\n",
    "\n",
    "# Save our result (model checkpoints, loss_acc data, plots)to this directory\n",
    "saved_model_dir = './model_performance_results/resnet_baseline_results/'\n",
    "\n",
    "model_name = 'resnet50'\n",
    "\n",
    "# Number of classes in  the dataset\n",
    "num_classes = 5\n",
    "\n",
    "# Batch size for training (standardized to BagNet baseline)\n",
    "batch_size = 32\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Some Helper Functions ---------------------------\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"\n",
    "    This function sets all parameters of model to False, which means we don't fine\n",
    "    tune all parameters but only feature extract and compute gradients\n",
    "    for newly initialized layer.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    \"\"\"\n",
    "    This function initializes these variables which will be set in this\n",
    "    if statement. Each of these variables is model specific.\n",
    "    \"\"\"\n",
    "    model_ft = None\n",
    "\n",
    "    if model_name == \"resnet50\":\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "\n",
    "    # Change the last layer\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    return model_ft\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[Using\", device , \"...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- Load and modify models ------------------------------\n",
    "model_ft_resnet = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "model_ft_resnet = model_ft_resnet.to(device)\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft_resnet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft_resnet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft_resnet = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# Setup the loss fxn\n",
    "print(\"[Using CrossEntropyLoss ...]\")\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- Load test datasets ------------------------------#\n",
    "\n",
    "print(\"==> [Preparing data ....]\")\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),  # resize the image to 224*224 pixels\n",
    "        transforms.CenterCrop(224),  # crop the image to 224*224 pixels about the center\n",
    "        transforms.RandomHorizontalFlip(),  # convert the image to PyTorch Tensor data type\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Just normalization for validation\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_data = torchvision.datasets.ImageFolder(data_dir + \"train/\", data_transforms[\"train\"])\n",
    "val_data = torchvision.datasets.ImageFolder(data_dir + \"val/\", data_transforms[\"val\"])\n",
    "test_data = torchvision.datasets.ImageFolder(data_dir + \"test/\", data_transforms[\"test\"])\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {\"train\": torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                    shuffle=True, num_workers=2),\n",
    "                    \"val\": torch.utils.data.DataLoader(val_data, batch_size=batch_size,\n",
    "                    shuffle=False, num_workers=2),\n",
    "                    \"test\": torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                    shuffle=False, num_workers=2)}\n",
    "\n",
    "train_loader = dataloaders_dict['train']\n",
    "val_loader = dataloaders_dict['val']\n",
    "test_loader = dataloaders_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- Load saved weights --------------------------------\n",
    "checkpoint = torch.load(saved_model_dir + \"resnet50_baseline_model.pth\", map_location=device)\n",
    "model_ft_resnet.load_state_dict(checkpoint['model_resnet50_state_dict'])\n",
    "optimizer_ft_resnet.load_state_dict(checkpoint['optimizer_resnet50_state_dict'])\n",
    "print(\"--------Saved resnet50 weights loaded--------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
