{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bagnets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce0b1eb0360e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbagnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorchnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[libraries successfully installed...]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bagnets'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS FILE CONTAINS CODE TO EVALUATE THE SAVED RESNET-50 MODEL ON THE TEST SET.\n",
    "\n",
    "CREDITS: Much of this code was selectively borrowed and adapted from: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "train_on_gpu = True\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "try:\n",
    "    import torchbearer\n",
    "except:\n",
    "    !pip install torchbearer\n",
    "    import torchbearer\n",
    "from torchbearer import Trial\n",
    "import scipy\n",
    "import scipy.special\n",
    "import bagnets.pytorchnet\n",
    "print(\"[libraries successfully installed...]\")\n",
    "\n",
    "\n",
    "#-------------------- Some Helper Functions ---------------------------\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"\n",
    "    This function sets all parameters of model to False, which means we don't fine\n",
    "    tune all parameters but only feature extract and compute gradients\n",
    "    for newly initialized layer.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    \"\"\"\n",
    "    This function initializes these variables which will be set in this\n",
    "    if statement. Each of these variables is model specific.\n",
    "    \"\"\"\n",
    "    model_ft = None\n",
    "\n",
    "    if model_name == \"bagnet\":\n",
    "        model_ft = bagnets.pytorchnet.bagnet33(pretrained=use_pretrained)\n",
    "    if model_name == \"resnet\":\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "\n",
    "    # Change the last layer\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    return model_ft\n",
    "\n",
    "\n",
    "#--------------------- Load test datasets ------------------------------\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),  # resize the image to 224*224 pixels\n",
    "        transforms.CenterCrop(224),  # crop the image to 224*224 pixels about the center\n",
    "        transforms.RandomHorizontalFlip(),  # convert the image to PyTorch Tensor data type\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Just normalization for validation\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"[Initializing test datasets and dataloaders...]\")\n",
    "\n",
    "# Create test datasets\n",
    "image_datasets = {x: datasets.ImageFolder(\"./data/test\", data_transforms[x])\n",
    "                  for x in [\"train\", \"test\", \"val\"]}\n",
    "\n",
    "# Create test dataloaders\n",
    "batch_size = 32\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=4)\n",
    "                    for x in [\"train\", \"test\", \"val\"]}\n",
    "\n",
    "train_loader = dataloaders_dict[\"train\"]\n",
    "val_loader = dataloaders_dict[\"val\"]\n",
    "test_loader = dataloaders_dict[\"test\"]\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[Using\", device , \"...]\")\n",
    "\n",
    "\n",
    "#--------------------- Load and modify models ------------------------------\n",
    "\n",
    "feature_extract = True\n",
    "model_name = 'resnet'\n",
    "num_classes = 5\n",
    "model_ft_resnet = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "model_ft_resnet = model_ft_resnet.to(device)\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft_resnet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft_resnet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft_resnet = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# Setup the loss fxn\n",
    "print(\"[Using CrossEntropyLoss ...]\")\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- Load saved weights --------------------------------\n",
    "\n",
    "checkpoint = torch.load(\"./resnet50_baseline_model.pth\", map_location=device)\n",
    "model_ft_resnet.load_state_dict(checkpoint['model_resnet50_state_dict'])\n",
    "optimizer_ft_resnet.load_state_dict(checkpoint['optimizer_resnet50_state_dict'])\n",
    "print(\"--------Saved resnet50 weights loaded--------------------\")\n",
    "\n",
    "\n",
    "#--------------- Investigate performance on test datasets ----------\n",
    "\n",
    "print(\"--------Investigate performance on test datasets---------\")\n",
    "trial = Trial(model_ft_resnet, optimizer_ft_resnet, criterion, metrics=['loss', 'accuracy']).to(device)\n",
    "trial.with_generators(train_loader, val_generator=val_loader, test_generator=test_loader)\n",
    "predictions = trial.predict()\n",
    "predicted_classes = predictions.argmax(1).cpu()\n",
    "\n",
    "\n",
    "#--------------- Some model performance visualizations & stats ----------\n",
    "\n",
    "'''\n",
    "CREDITS: Code adapted from tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n",
    "'''\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Define classes\n",
    "classes = ('daisy', 'dandelion', 'rose', 'sunflower', 'tulip')\n",
    "\n",
    "# Show ground truth (4 images with labels)\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# Check class prediction accuracies\n",
    "class_correct = list(0. for i in range(5))\n",
    "class_total = list(0. for i in range(5))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft_resnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        if c.size()[0] == 4:\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
